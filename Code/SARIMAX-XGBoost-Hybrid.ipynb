{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90765,"databundleVersionId":10583383,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ta","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T04:42:03.177864Z","iopub.execute_input":"2025-01-06T04:42:03.178068Z","iopub.status.idle":"2025-01-06T04:42:09.576055Z","shell.execute_reply.started":"2025-01-06T04:42:03.178047Z","shell.execute_reply":"2025-01-06T04:42:09.575062Z"}},"outputs":[{"name":"stdout","text":"Collecting ta\n  Downloading ta-0.11.0.tar.gz (25 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ta) (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ta) (2.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.16.0)\nBuilding wheels for collected packages: ta\n  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=afa0b5a64992f57ce9659c37f541005551acdfb3eebb0909b0dedb40f2ee4b4c\n  Stored in directory: /root/.cache/pip/wheels/5f/67/4f/8a9f252836e053e532c6587a3230bc72a4deb16b03a829610b\nSuccessfully built ta\nInstalling collected packages: ta\nSuccessfully installed ta-0.11.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\nimport ta\nfrom sklearn.preprocessing import StandardScaler\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nimport xgboost as xgb\nfrom concurrent.futures import ThreadPoolExecutor\nimport gc\n\nwarnings.filterwarnings('ignore')\n\nclass TimeSeriesModel:\n   def __init__(self):\n       self.sarimax_model = None\n       self.xgb_model = None\n       self.scaler = StandardScaler()\n\n   def _calculate_momentum(self, df):\n       result = pd.DataFrame(index=df.index)\n       result['rsi'] = ta.momentum.RSIIndicator(df['close'], window=14).rsi()\n       result['macd'] = ta.trend.MACD(df['close'], window_fast=12).macd()\n       result['atr'] = ta.volatility.AverageTrueRange(\n           df['high'], df['low'], df['close'], window=14\n       ).average_true_range()\n       return result\n\n   def _calculate_volume(self, df):\n       result = pd.DataFrame(index=df.index)\n       result['volume_ma_10'] = df['volume'].rolling(window=10, min_periods=1).mean()\n       result['volume_ratio'] = df['volume'] / result['volume_ma_10']\n       return result\n\n   def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n       df = df.copy()\n\n       # Shift base data\n       base_cols = ['close', 'high', 'low', 'volume']\n       df[base_cols] = df[base_cols].shift(1)\n\n       # Returns calculations\n       df['returns'] = df['close'].pct_change()\n\n       # Parallel indicator calculation\n       with ThreadPoolExecutor(max_workers=2) as executor:\n           futures = {\n               executor.submit(self._calculate_momentum, df): 'momentum',\n               executor.submit(self._calculate_volume, df): 'volume'\n           }\n\n           for future in futures:\n               result = future.result()\n               df = pd.concat([df, result], axis=1)\n\n       # Time features\n       timestamp = pd.to_datetime(df['timestamp'], unit='s')\n       df['hour'] = timestamp.dt.hour\n       df['day_of_week'] = timestamp.dt.dayofweek\n\n       return df.fillna(0)\n\n   def prepare_features(self, df: pd.DataFrame) -> np.ndarray:\n       exog_columns = [\n           'returns',  # price movement\n           'volume_ratio',  # volume trend\n           'rsi',  # momentum\n           'macd',  # trend\n           'atr',  # volatility\n           'hour', 'day_of_week'  # time features\n       ]\n\n       exog = df[exog_columns]\n       return self.scaler.fit_transform(exog) if self.sarimax_model is None else self.scaler.transform(exog)\n\n   def train(self, train_data: pd.DataFrame):\n       df = self.calculate_technical_indicators(train_data)\n\n       # Sample last 50K rows for SARIMAX\n       sarimax_df = df.iloc[-50000:].copy()\n       sarimax_exog = self.prepare_features(sarimax_df)\n\n       self.sarimax_model = SARIMAX(\n           sarimax_df['close'],\n           exog=sarimax_exog,\n           order=(1, 1, 0),\n           seasonal_order=(0, 1, 1, 12)\n       ).fit(disp=False, method='powell')\n\n       # Full data for XGBoost\n       X = self.prepare_features(df)\n       y = (df['close'].diff() > 0).astype(int)\n\n       self.xgb_model = xgb.XGBClassifier(\n           n_estimators=200,\n           learning_rate=0.05,\n           max_depth=6,\n           tree_method='gpu_hist',\n           predictor='gpu_predictor',\n           grow_policy='lossguide',\n           max_leaves=32,\n           n_jobs=-1,\n           subsample=0.9,\n           colsample_bytree=0.9,\n           min_child_weight=3,\n           gamma=1,\n           eval_metric='logloss',\n           random_state=42\n       )\n       self.xgb_model.fit(X, y)\n\n       gc.collect()\n\n   def predict(self, future_df: pd.DataFrame) -> np.ndarray:\n       df = self.calculate_technical_indicators(future_df)\n       exog = self.prepare_features(df)\n\n       sarimax_forecast = self.sarimax_model.forecast(steps=len(df), exog=exog)\n       xgb_pred = self.xgb_model.predict_proba(exog)[:, 1]\n\n       return ((sarimax_forecast.diff() > 0).astype(float) * 0.4 + xgb_pred * 0.6 > 0.5).astype(int)\n\n\ndef main():\n   try:\n       chunk_size = 500000\n       chunks = []\n\n       for chunk in pd.read_csv('/kaggle/input/directional-forecasting-cryptocurrencies/train.csv',\n                                usecols=['timestamp', 'close', 'high', 'low', 'volume'],\n                                chunksize=chunk_size):\n           chunks.append(chunk)\n\n       train_df = pd.concat(chunks)\n       chunks = None\n       gc.collect()\n\n       test_df = pd.read_csv('/kaggle/input/directional-forecasting-cryptocurrencies/test.csv',\n                             usecols=['timestamp', 'close', 'high', 'low', 'volume'])\n\n       print(\"Training model...\")\n       model = TimeSeriesModel()\n       model.train(train_df)\n\n       print(\"Generating predictions...\")\n       predictions = model.predict(test_df)\n\n       pd.DataFrame({\n           'row_id': range(len(predictions)),\n           'target': predictions\n       }).to_csv('submission.csv', index=False)\n\n       print(f\"Predictions generated: {len(predictions)}\")\n\n   except Exception as e:\n       print(f\"Error: {str(e)}\")\n\n\nif __name__ == \"__main__\":\n   main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T04:42:09.576906Z","iopub.execute_input":"2025-01-06T04:42:09.577140Z","iopub.status.idle":"2025-01-06T04:50:16.584676Z","shell.execute_reply.started":"2025-01-06T04:42:09.577118Z","shell.execute_reply":"2025-01-06T04:50:16.583856Z"}},"outputs":[{"name":"stdout","text":"Training model...\nGenerating predictions...\nPredictions generated: 909617\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"0.49855","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}